---
title: 
tags:
  - spark
---
- allows you to schedule >=1 task as job for orchestration
- executing notebook (databrick/git) or pipeline
- schedule by time (cannot set end date)
- Email notification
- permission (run/ view/ manage)
- "repair run" => only rerun the part that failed

On **Depends on** field, one prior task should be selected for currently editing task
To check the progress of the run, navigate to the Runs tab in the Jobs UI and click on the active run to review the processing notebook
To reduce the start up time, use job cluster from a **cluster pool**, which are pre-provision